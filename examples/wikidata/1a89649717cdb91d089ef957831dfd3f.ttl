@prefix sh: <http://www.w3.org/ns/shacl#> .
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix dcterms: <http://purl.org/dc/terms/> .
@prefix schema: <https://schema.org/> .

<https://www.wikidata.org/#query-1a89649717cdb91d089ef957831dfd3f> a sh:SPARQLExecutable,
    sh:SPARQLSelectExecutable;
  rdfs:comment """ This page is an archive. Please do not modify it. Use the current page, even to continue an old discussion. Contents 1 problem with \"quantity\" datatype for properties.... 2 Bahamas Leaks 3 Deboosting scholarly article (Q13442814) 4 Erroneous request for merging 5 Please remove items 6 AGPL vs. AGPL 7 Excel file as a source 8 Calendario Gregoriano 9 Wikidata weekly summary #293 10 Quality control and constraints on subsets 11 Search anomaly \"nap\" 12 Importing data about electric vehicle charging stations 13 Changing data type 14 How to merge 15 Population property and census item 16 Constraints about villages 17 Interlanguage links with anchors and redirects 18 Renaming a maintenance category 19 Change on the editing interface: save becomes publish 20 Is it worth contributing to pywikibot? 21 How to improve the usefulness of Wikidata descriptions? 22 Monuments 23 Format of Polish cultural heritage register number (P3424): reference in a Polish cultural heritage register 24 Format of LAU (P782): identifier for a local administrative unit, renamed from NUTS 4 and NUTS 5. Format: 2 letters followed by digits 25 Geocodes of Cyprus 26 Signs displaying the name of a place where they are not situated 27 Inconsistencies between Q937130, Q3540821, and Q788723 28 Civil Rights Memorial 29 Worldcat Identities 30 Produced sound 31 Free image available at url property? 32 Area precision 33 Time to split Wikidata:List_of_properties/Terms 34 Intercardinal direction items - constraint 35 How does Wikidata handle projected data? 36 Idiot's guide to add interwiki link? 37 Film narration in different languages 38 2017 Chile census 39 Rules for linking to WD from WP 40 Dataset on typhoon warning messages issued by authority 41 The Giant Turnip (Q2068935) 42 Books and articles 43 Wikidata weekly summary #294 44 Recoin now available as gadget 45 toclimit 46 Wikidata data model \"deficiency\" 47 Wikidata in read-only for 30min on January 9th 48 How to query old revisions of items? 49 Google Knowledge Graph API 50 How to model 'infant mortality rate'? 51 License page? 52 Format of Isidore scholar ID (P4491): identifier of a scholar on Isidore, a platform that collects links to scholarly documents and academic official texts 53 Box office in visitors 54 Custom javascript breaking other scripts 55 Cleanup of unsourced ‚Äúethnic group (P172)‚Äù claims 56 PetScan 57 Titles for painting (Q3305213) 58 pywikibot / iterating over SPARQL causes error 59 List of properties directly related to Wikimedia projects 60 Translate \"publish\" 61 Castles as occurrences ??? 62 Ink Master Spin Off Show Data 63 Query Service 64 Python problem 65 Search without 'scientific articles' 66 Cyprus places at the north part 67 Creating many items 68 Next IRC office hour on January 30th 69 Facto Post ‚Äì Issue 8 70 Making P18 values usable 71 Opening days and prices 72 Wikidata weekly summary #295 73 Gadget for Scholia? 74 English Wikipedia banned links to Wikidata 75 Two elements on the same concept have different links to Wikipedia in Arabic 76 Structure of compound=structure of molecule? 77 Newly created items are not available. 78 Using data on software versions from Wikidata in Repology project 79 Retracted papers 79.1 Subclass as a variable property 80 Lua request for form 81 List of mayors redux 82 Best practice - list and not-lists 83 Gary Auerbach (Q5524624) - Gary Auerbach (Q3098512) a probable mess 84 Also known as ... symbol 85 Should we re-allow country (P17)-Scotland (Q22)? 86 P4020 format 87 Units with quickstatements 88 hilarri (Q1391249) and discoid stele (Q16678077) 89 Research in programming Wikidata 90 Patron saint 91 HTML formatting (italics, superscript and subscript) in labels 92 Titus Atilius Rufus is not American Treaty Shore 93 Merge help 94 Date 95 Centuries 96 Converting Latin names to statement Q codes 97 formatter URL (P1630) - distinct values constraint 98 Dates when a style or item \"flourished\" 99 source website for the property (P1896) 100 Petscan question 101 Creating a redirect 102 Aliases of Pieter Brueghel the Elder (Q43270) 103 Specify located in time zone (P421) (and similar properties) on every place or just the most expansive place only? 104 Formatter URLs for DOIs 105 Module:Wikidata handle novalue 106 Wikidata weekly summary #296 107 Quick community survey: deletion of items about ‚Äúrelatively unknown persons‚Äù on their own request 108 Production - help? 109 Bonnie and Clyde problems 110 ?action=edit 111 Alexa rank (P1661) for a municipality? 112 Sources in the average Wikipedia infobox 113 Governors of US territories who refuse their appointment 114 Preventing to merge disambiguation items with regular items 115 Tool for easily searching for a specific ID (Viaf, Bnf, IMDb, etc.) 116 Unified login 117 Creaci√≥n de un nuevo actor de doblaje 118 10k 404 URLs for Cultural Heritage Agency of the Netherlands Art Collection 118.1 Another 16k Bavarian State Painting Collections URLs give 404 118.2 and now DACS ID (former) (P4663) 119 Documenting and describing PIDs 119.1 Side discussion 120 LCCN 121 Is there a Findagrave bot 122 Use of P1282 OpenStreetMap tag or key 123 Batang Gembira 124 Label bots 125 BREAKING CHANGE: wbcheckconstraints status parameter 126 WikidataJS grant proposal 127 Wikidata weekly summary #297 128 Automatically copied labels to other languages 129 Dams and reservoirs 130 Q529207 131 Format of references referring to an external database and distinct values constraint 132 Historical visual diffs (beta feature) 133 Organizing consolidated city/counties 134 Instance completeness 134.1 And part completeness 135 Lack of admin attention 136 Towards aligning Wikidata and Wikipedia infoboxes 137 Ontology of general elections and local results 138 Better property for frequency of first names 139 Changing the property of a statement 140 Edit request at Property_talk:P356#EIDR 141 Query Helper on WDQS 142 Country of citizenship is Wales 142.1 Source based approach 143 Q7307505 144 What tool is available to automate ... problem with \"quantity\" datatype for properties.... Hi,all properties with quantity datatype have the type indicated in greek in fr-interface as can be seen on this screencapture !! how is it possible to correct this, please ? I could not find the page that allows translation from \"quantity\" :( --Hsarrazin (talk) 14:14, 3 January 2018 (UTC) I think it's the translate-wiki message for MediaWiki:Datatypes-type-quantity/fr. --- Jura 15:11, 3 January 2018 (UTC) exact... thanks Jura :) what bothers me is translatewiki has been corrected almost 2 weeks ago [1] but I still get wrong input in greek (el) instead of fr. Purging MediaWiki:Datatypes-type-quantity/fr did nothing... - is there a lagging problem, or is it something else that I cannot see ? --Hsarrazin (talk) 16:16, 3 January 2018 (UTC) @Hsarrazin: Translations have to be deployed like code changes, and there were no deployments over the holiday period. If I‚Äôm not mistaken, the next Wikidata deployment should happen in a few hours (20:00 ‚Äì 22:00 UTC, see the ‚ÄúMediaWiki train‚Äù in wikitech:Deployments#Wednesday, January 03). --Lucas Werkmeister (WMDE) (talk) 17:12, 3 January 2018 (UTC) Seems to be fixed now :) at least I now see ¬´Quantit√©¬ª on Property talk:P4714?uselang=fr --Lucas Werkmeister (WMDE) (talk) 12:11, 4 January 2018 (UTC) This section was archived on a request by: Lucas Werkmeister (WMDE) (talk) 12:11, 4 January 2018 (UTC) Bahamas Leaks Could a Japanese or Chinese speaker say whether Bahamas Leaks (Q27021541) and Bahamas Leaks (Q27449990) should be merged, please? Andy Mabbett (Pigsonthewing); Talk to Andy; Andy's edits 17:58, 3 January 2018 (UTC) Done Google translate indicates that they are the same subject matter, with document counts, and dates. ‚Äî billinghurst sDrewth 03:11, 4 January 2018 (UTC) This section was archived on a request by: Matƒõj Such√°nek (talk) 07:36, 5 January 2018 (UTC) Deboosting scholarly article (Q13442814) I've received a number of requests to apply same de-boosting in search rankings as we do for disambiguation pages to items that are instance of (P31) scholarly article (Q13442814). I think it makes sense, since these articles, by their nature, match a lot of terms, but usually they are not the item one looks for when searching for things (i.e., if you look for \"dog\", you'd probably expect stuff related to dog (Q144) on top and not all scientific articles mentioning dogs, at least not on top). Thus, I plan to apply some negative adjustment to their rankings. Note that this would not remove them from search results, just make them rank lower. I would like to hear if anybody sees any problems or can bring any objections to this? If there's no strong opposition, this will be done somewhere in January, once the holiday deployment freeze is over. Smalyshev (WMF) (talk) 21:47, 21 December 2017 (UTC) Support Pamputt (talk) 22:02, 21 December 2017 (UTC) Support Mahir256 (talk) 22:29, 21 December 2017 (UTC) Sorry, searching for \"dog\" (I switched to enUI) gives no top results marked as scholarly article (Q13442814). --Succu (talk) 22:45, 21 December 2017 (UTC) \"dog\" is likely no good example. \"heart rhythm\" was one example that I suggested that led to this change. In the new search (http://wikidata-wdsearch.wmflabs.org/wiki/Special:Search) it didn't show in the top 500 items at the time. In general it's often hard to find items for technical terms that are similar to \"heart rhythm\" when the items don't have much use. ChristianKl ‚ù™‚úâ‚ù´ 01:43, 22 December 2017 (UTC) Then maybe implementing search options like \"-scientific article\" are a better way to follow. --Succu (talk) 20:07, 22 December 2017 (UTC) I agree, having such option would be nice. But: a) it's not possible to use it in completion suggesters and b) implementing an option will take time (we'd need to do some refactoring work on underlying parser, probably) and boosts are available right now. Smalyshev (WMF) (talk) 20:14, 22 December 2017 (UTC) Sorry, Stas but I have no idea what ‚Äûboosts‚Äú are? --Succu (talk) 22:50, 22 December 2017 (UTC) @Succu: Changes in search score (and thus ranking) of certain items according to certain rule (in this case, value of instance of (P31)). Smalyshev (WMF) (talk) 22:52, 22 December 2017 (UTC) And how does that help users searching for scientific articles? Andy Mabbett (Pigsonthewing); Talk to Andy; Andy's edits 23:26, 21 December 2017 (UTC) Can you give specific queries of how you see users seeking scientific articles? ChristianKl ‚ù™‚úâ‚ù´ 01:21, 22 December 2017 (UTC) Andy, that was pretty indelicate. :-/ I would think that a statement along the lines, of \"good initiative, though we also need to look to how people wishing to search for scientific articles, or other entity based search, are able to perform searches more functionally to get results.\" Would get a response of \"good point, let us see what we can do\" rather then \"sit and spin Captain Grumpy\". I support Smalyshev's suggestion though do share Andy's concerns. ‚Äî billinghurst sDrewth 13:17, 22 December 2017 (UTC) The problem with even your reformulated version is that it contains no concrete ideas of what kind of queries Andy has in mind where this would be a problem. If you do share his concerns, do you have specific queries in mind? Having specific examples would be helpful for discussing the effects. ChristianKl ‚ù™‚úâ‚ù´ 19:43, 22 December 2017 (UTC) I have no idea of Andy's desires in the area. If you are asking what I consider possible, well freethinking how about biographical article (Q19389637) for George Washington (Q23)? Do I pine for it now? No. Is it a particular search we would like to be able to be run internally, I would think so if we want to have described by source (P1343) filled with our sources. PS. I didn't add examples as I didn't think that it was that great a leap of invention. ‚Äî billinghurst sDrewth 01:55, 23 December 2017 (UTC) Basically your idea is that articles about George Washington should be ranked higher than people called George Washington? Even without any deranking of scientific articles, George Washington Lane (Q5545995) that's currently on place 100 ranks higher than any scientific article. Searching scientific articles on Google Scholar is much more efficient than doing so on Wikidata. On the other hand if you searh the item for a person on Wikidata who shares it's name with 30 other people you are dependent on the Wikidata search engine. ChristianKl ‚ù™‚úâ‚ù´ 15:29, 23 December 2017 (UTC) No mate, you miss my point. Sometimes I think that you need to stand back a little further and see what is being said. On this forget it, I am not in the mood. ‚Äî billinghurst sDrewth 21:25, 24 December 2017 (UTC) The fact that I take your answer as being an answer to the question I asked, doesn't seem to me as needing to take a step back. I asked for examples because I can't think of examples where I think it's valuable to not downrank the scientific articles. ChristianKl ‚ù™‚úâ‚ù´ 19:55, 26 December 2017 (UTC) Unsurprisingly, Smalyshev's reply was far more civil than you suggested it would be. Andy Mabbett (Pigsonthewing); Talk to Andy; Andy's edits 21:35, 24 December 2017 (UTC) It wouldn't help when you search for scientific article, of course, the article would be appearing lower in ranking. The ranking in general is the game of tradeoffs - you frequently find many more results that you can display, and of course only one can be the first, so you need to try and guess what the user means. One approach is to optimize for the common case - which means the users with an uncommon case would have it slightly worse, and the users with common case for have it slightly better. As we add more syntax to it (which will happen eventually, at least for fulltext search) it would be easier to tell the engine what you are looking for, but there will always be tradeoffs. So what I am trying to do is to find a set of tradeoffs with more optimal summary usability. Smalyshev (WMF) (talk) 20:30, 22 December 2017 (UTC) Support but @Smalyshev (WMF): I think a better general solution rather than de-boosting rank of particular P31 values is to look at the length of the label: shorter labels that contain the search string would in general be more likely to match what the searcher was looking for, and scientific articles (among other less likely matches) generally have much longer labels. Though maybe that should apply only with the main label and not aliases (which can be just abbreviations). Another option I'd like to see: allow an advanced search option that lets you deliberately filter by including or excluding common P31 values (Q5, Q13442814, ...), similar to how search can now be filtered by namespace. ArthurPSmith (talk) 14:27, 22 December 2017 (UTC) Interesting idea, I will check if this is feasible. Smalyshev (WMF) (talk) 20:14, 22 December 2017 (UTC) I would be in favour of such advanced search options that allow to combine the text search and/or completion suggestors with elements of the semantic graph. Not sure deboosting is the best approach for the specific issue at hand ‚Äî label length and perhaps something closer to tf‚Äìidf (Q796584) would seem more promising, especially if they could be tuned by the users as they work on different things at different points in time (e.g. on cardiology-related topics today, on matching papers tomorrow). --Daniel Mietchen (talk) 22:34, 1 January 2018 (UTC) Support. Or we should change the search algorithm so that a search needs to match a certain proportion of keywords in the title of a scientific article for it to float onto the top of a result... Deryck Chan (talk) 14:54, 22 December 2017 (UTC) Erroneous request for merging Hello. I have just been requesting an item for merging, but I found out that this was a mistake. Any suggestions to what I can do? The item is Q12320419, which I tried to merge into Q1857341. In my attempt I ended by pressing a Postpone-button - I am not quite sure, what this does, but I supposed it put the request in some sort of queue, and eventually the merging takes place.I am sorry for the problems, I've created. --Amjaabc (talk) 10:16, 27 December 2017 (UTC) Christmas Holiday (Q1857341) describe a film from 1944. Are you sure you want to merge Christmas break (Q12320419) into it? --Pasleim (talk) 13:05, 27 December 2017 (UTC) \"I found out that this was a mistake. Any suggestions to what I can do\" Mateusz Konieczny (talk) 16:57, 27 December 2017 (UTC) As you can see, this button will do nothing with those items. It is supposed to save the item id for later but I'm not sure whether it still works. Matƒõj Such√°nek (talk) 09:31, 28 December 2017 (UTC) Sure, but @Sjoerddebruin: doesn't seem agree. --Liuxinyu970226 (talk) 04:23, 2 January 2018 (UTC) Please remove items Please remove all speculative items at Star Wars Episode IX: The Rise of Skywalker (Q20977110). The principal photography is only set to begin in half a year! Maybe it never will, maybe people will leave the project or even be dead by then. Wikidata should contain definite data and not speculations! --88.71.165.225 16:02, 29 December 2017 (UTC) Done a little pruning and left a note on the item's talk page. It is just one of those things, planned/contracted/actuality <shrug> all can be argued to be valid. ‚Äî billinghurst sDrewth 13:48, 1 January 2018 (UTC) AGPL vs. AGPL Happy new year! Now I have a question which asked last year but still haven't any answers, specifically about those items: GNU Affero General Public License (Q1131681) Affero General Public License (Q28130012) Affero General Public License, version 1.0 (Q27017230) GNU Affero General Public License, version 3.0 (Q27017232) GNU Affero General Public License, version 3.0 or later (Q27020062) Both enwiki and ptwiki are having separated articles, describe different histories of different AGPL, but in many other languages they say both are same, with just a potential purchasing from GNU, to the best of my knowledge merging any two or more of them won't be helpful, and unlikely be possible, so how do I do something for them? --Liuxinyu970226 (talk) 01:44, 1 January 2018 (UTC) As I mentioned at WD:IC, I temporary marked second as Wikimedia permanent duplicate item (Q21286738). --Liuxinyu970226 (talk) 01:45, 1 January 2018 (UTC) Affero General Public License, version 1.0 (Q27017230) is the same as Affero General Public License (Q28130012), as there is zero chance of another version of the original non-GNU Affero GPL. IMO they should be merged. Likewise GNU Affero General Public License, version 3.0 (Q27017232) is the same as GNU Affero General Public License (Q1131681). In this case, there is a chance of another version of the license being established, and in addition there is often legal wording like \"version 3.0 or later\" vs \"version 3.0\" (and not later), so there could be a case for Q28130012, Q27017232 and Q27020062 being considered to be separate items covering slightly different concepts. But I find that to be too much extra complexity without any real world use cases to justify it. All Wikipedia articles will be talking mostly about the (unversioned) GNU AGPL, as that is the name of the 'most commonly used' concept in this area, and the history of GNU AGPL is included in those article. John Vandenberg (talk) 16:44, 2 January 2018 (UTC) Excel file as a source If a source is an excel file:1) How can we use file format (P2701)? With Microsoft Excel (Q11272)?2) Is there a property to show in which sheet the data is?Xaris333 (talk) 03:36, 2 January 2018 (UTC) Excel is a software and not a file format. The item on excel lists the various file formats it can deal with under readable file format (P1072). ChristianKl ‚ù™‚úâ‚ù´ 11:00, 2 January 2018 (UTC) Calendario Gregoriano In English: publication date 4 April 1881 GregorianIn Greek: Œ∑ŒºŒµœÅŒøŒºŒ∑ŒΩŒØŒ± Œ¥Œ∑ŒºŒøœÉŒØŒµœÖœÉŒ∑œÇ 4 ŒëœÄœÅŒπŒªŒØŒøœÖ 1881 Calendario GregorianoCalendario Gregoriano is now Greek. How can I change it?Xaris333 (talk) 04:05, 2 January 2018 (UTC) ‚Üítranslatewiki:MediaWiki:Wikibase-time-calendar-gregorian/el. Seems that somebody experimented or chose wrong language. Matƒõj Such√°nek (talk) 13:44, 2 January 2018 (UTC) Wikidata weekly summary #293 Here's your first Wikidata Weekly Summary of the year 2018 (Calendar: Gregorian)! Events/Press/Blogs Past: Wikidata team and volunteers were at 34C3. Check the videos, the tweets, a new design made by Bleeptrack for a cake. Videos of Wikidata-related workshops will be published soon. Upcoming: Cultural heritage Wikidata workshop in Prague, 13th January 2018 Using Scholia as Open Notebook Science tool to support literature searching Other Noteworthy Stuff New tool that allow users to fill labels and descriptions to Wikidata items en masse Change on the editing interface: save becomes publish. Please help translating in your language and update documentation Did you know? Newest properties: Minneapolis Institute of Art ID, CHGIS ID, Guardiana ID, Barnes Foundation ID, VOGRIPA ID, Rugby Canada ID, Ent'revues ID, World of Spectrum ID, Smithsonian American Art Museum ID, HATVP ID, Google Arts & Culture partner ID, Google Arts & Culture asset ID, Cairn journal ID, Canal-U channel ID, Conseil de Presse Luxembourg journalist ID, Historic Place Names of Wales ID, CIQUAL2017 ID, GEMS Code, Arquivo Arq ID, Argentine deputy ID, American Art Collaborative object ID Query examples: Landlocked countries bordering coastal countries (source) Most common years of birth in Wikidata (source) Map of lighthouses around the world (source) Bubble chart showing countries with the highest number of children out of school in 2013 (source) Playwright dead in 1947 (whose works are now in Public Domain) (source) Development Fixed a problem with references in history of items (phab:T182767) Thanks to Matƒõj Such√°nek who helped providing a workaround Make statements on forms persistent for lexicographical data (phab:T163724) Fix a bug that removed the collapse button (phab:T175492) Remove cache constraint check results on purge (phab:T182107) Add sitelinks to hif.wiktionary (phab:T180785) Read constraint check results from cache and check freshness (phab:T182106) Re-label the \"Save\" links to \"Publish\" (phab:T161367) You can see all open tickets related to Wikidata here. Monthly Tasks Add labels, in your own language(s), for the new properties listed above. Comment on property proposals: all open proposals Suggested and open tasks! Contribute to a Showcase item. Help translate or proofread the interface and documentation pages, in your own language! Help merge identical items across Wikimedia projects. Help write the next summary! Read the full report ¬∑ Unsubscribe ¬∑ Lea Lacroix (WMDE) 14:43, 2 January 2018 (UTC) Quality control and constraints on subsets I've been working on improving quality mostly related to paintings. Quality has different aspects. I'm currently looking at completeness. For example every painting (Q3305213) should have a creator (P170), should be in a collection (P195), has at least one creator (P170), should have inception (P571), etc etc. One way to do this is to set constraints on certain properties, but this only works if you happen to have a property that covers your interest. Because the numbers are rather large, I focus on subsets. For example Wikidata:WikiProject sum of all paintings/Wiki monitor/nlwiki only looks at painting items that have a link to the Dutch Wikipedia. This makes it more humans scale. You can actually finish it and keep the quality standard for this subset. The sum of all paintings category contains many more examples of subsets.This all doesn't scale very well. Wouldn't it be nice to have some sort of tool to assist in this? Some sort of next generation constraints or Recoin? As a user I would like to set a focus area (in this case instance of (P31) painting (Q3305213)). The tool would offer property coverage and intersections. A user could work on a subset and add the missing data. The next step would be to be able to flag subsets with things like \"I'm working on this\", \"cleared it\" or maybe even \"needs bot import\". A user could come back later or get a report of all the cleared subsets which need some attention (like Listeria updating the report page).Do you think this is feasible? Would this be something to work on in 2018? Multichill (talk) 16:56, 30 December 2017 (UTC) Why doesn't listeria do the job? ChristianKl ‚ù™‚úâ‚ù´ 18:06, 30 December 2017 (UTC) It's all static, it doesn't scale. You have to make a report yourself for everything. Multichill (talk) 11:38, 31 December 2017 (UTC) I have the impression that working through work lists takes a lot more time than creating worklists. Sure it would be possible to make the creation of worklist easier, but I would expect that will result in a lot of work lists with undone tasks. ChristianKl ‚ù™‚úâ‚ù´ 11:53, 31 December 2017 (UTC) This Recoin idea would be nice to have for Wikidata:WikiProject Women too. Items should have a few basic human (Q5)-related properties, plus some guidelines about occupation (P106), especially for women born before 1850 who could not be professionally trained but whose occupation is still more than \"daughter\", \"wife\", \"mother\", or \"noble\". After working on various women items I am starting to see some trends, but it is slow-going by hand. It would be nice to be able to generate some specific reports on the fly for certain occupations. Jane023 (talk) 11:57, 31 December 2017 (UTC) Ping Ls1g about Recoin. @Multichill what you want to have looks a lot like the features provided by SHACL. It is an RDF vocabulary done in order to express constraints on the RDF graph. It allows to express things like \"all the nodes that are results of this SPARQL query must have exactly one value for property X, may have values for property Y that are integers between 0 and 10 and must not have values for property Z. It could be nice to have a tool able to evaluate such constraints on Wikidata using the Query Service. Andrawaag have already done some investigation on using such constraints systems with Wikidata. Tpt (talk) 22:00, 31 December 2017 (UTC) We had some thoughts on building a tool for a similar purpose, so I am very curious to understand what you have in mind. What we were thinking of was something like shown on the right: After the user has specified a class, a set of properties that should be present, and a set of facets, the tool essentially shows the distribution of completeness wrt. the chosen properties along the chosen facets (mock shown on the right, inspired from Listeria examples). Mock Wikidata Profiling Tool That should work with Dutch paintings or humans of gender female as well, though to do anything beyond instanceOf, I guess a bit of SPARQL might be needed. Does that have some similarity with what you have in mind? What do you refer to with \"intersections\"? Cheers, Ls1g (talk) 19:37, 2 January 2018 (UTC) @Ls1g: intersection (Q185837) let's say all painting items are a set. The set of paintings that have an article in Dutch is a subset. The set of paintings that don't have a creator (P170) is another subset. These two combined (painting with article in Dutch, but no creator (P170)) would be an intersection. I want to do arbitrary intersections and keep track of them. With these intersections you get subsets of a size that humans can handle. Multichill (talk) 20:15, 2 January 2018 (UTC) Search anomaly \"nap\" When I type \"nap\" in the top right search box, neither nap (Q901586) nor nap (Q5242962) appears. This is annoying - I came close to creating a duplicate item because I could not find the one I was looking for. Can the search team explain what's happening here? Thanks! - PKM (talk) 19:41, 1 January 2018 (UTC) Neapolitan (Q33845) has the language code \"nap\" and therefore the alias nap. It has 76 sitelinks while the nap (Q901586)/nap (Q5242962) have less and only three statements each. The other hits also have \"nap\" as aliases. The new full text search does a more resonable job at finding the right items: http://wikidata-wdsearch.wmflabs.org/w/index.php?search=nap&title=Special:Search&profile=default&fulltext=1&searchToken=7m0erkmodnwn7r4kfya1yik51 https://www.wikidata.org/wiki/Wikidata:Suggester_ranking_input is a page for adding searches where the top right search box does a bad job. I invite you to add this example and any further you encounter to that page.ChristianKl ‚ù™‚úâ‚ù´ 11:00, 2 January 2018 (UTC) Thanks for that explanation! Will do. - PKM (talk) 20:03, 2 January 2018 (UTC) Importing data about electric vehicle charging stations Yesterday I tried out the Query:https://query.wikidata.org/#%23defaultView%3AMap%0ASELECT%20%3Fitem%20%3Fcoord%20%0AWHERE%20%0A%7B%0A%20%20%3Fitem%20wdt%3AP31%20wd%3AQ10373548.%0A%20%20%3Fitem%20wdt%3AP625%20%3Fcoord.%0A%7Dwhich gives me a world map of Whisky Distilleries.I was wondering why the Query https://query.wikidata.org/#%23defaultView%3AMap%0ASELECT%20%3Fitem%20%3Fcoord%20%0AWHERE%20%0A%7B%0A%20%20%3Fitem%20wdt%3AP31%20wd%3AQ2140665.%0A%20%20%3Fitem%20wdt%3AP625%20%3Fcoord.%0A%7Dstarting from https://www.wikidata.org/wiki/Q2140665does not work the same. I found something like: https://commons.wikimedia.org/wiki/Category:Electric_vehicle_charging_stations_in_GermanyBut nothing for official list of stations e.g. https://tank.rast.de/emobility/I would love to work on import for such data if that makes sense. So How much sense does the idea make? How to proceed? --WolfgangFahl (talk) 16:36, 2 January 2018 (UTC) Any import of missing information from realiable source is always appreciated. Matƒõj Such√°nek (talk) 19:06, 2 January 2018 (UTC) This is certainly useful information to import, assuming the source includes coordinates. I don't know how complete OpenStreetMap is, maybe openstreetmap:Tag:amenity=charging_station helps. Nemo 20:09, 2 January 2018 (UTC) The query does not work because there are no item about electric vehicle charging station (Q2140665) with coordinate location (P625) in Wikidata. Data about charging station in France (IRVE file): https://www.data.gouv.fr/fr/datasets/fichier-consolide-des-bornes-de-recharge-pour-vehicules-electriques-irve/ (decree). 20:39, 2 January 2018 (UTC) Changing data type Property:P627 has a data type of \"string\", but it should probably be \"external-id\" instead. I'm not that familiar with Wikidata -- what is the correct venue for requesting this change? --Ahecht (talk) 18:44, 2 January 2018 (UTC) There is a disagreement that this should happen, see Wikidata:Identifier migration/0#Not going to convert. It's not the first time this question is raised. Matƒõj Such√°nek (talk) 19:04, 2 January 2018 (UTC) It was also discussed at Wikidata:Project_chat/Archive/2015/10#About_Property:P627. --Jarekt (talk) 20:05, 2 January 2018 (UTC) How to merge Diagonalisierung (Q3025885) and Diagonalisierung (Q1208191) can be merged. How do I do this? Naively I would add Q1208191 to Q3025885 and then add ask for deletion for Q1208191. Thanks --Nobelium (talk) 11:19, 9 January 2018 (UTC) Try Help:Merge. --- Jura 11:25, 9 January 2018 (UTC) Done --Liuxinyu970226 (talk) 11:32, 9 January 2018 (UTC) This section was archived on a request by: Matƒõj Such√°nek (talk) 18:23, 9 January 2018 (UTC) Population property and census item Hello. I need a property to use as a qualifier to connect census item with the value of the population of a place. A user suggest statement is subject of (P805), but it is not a valid qualifier for population (P1082). I don't want to use stated in (P248) as a source. Xaris333 (talk) 00:10, 3 January 2018 (UTC) @Xaris333: Why not? P248 seems like the right way to do this. --Yair rand (talk) 00:16, 3 January 2018 (UTC) I don't want the census item to be the source. I have add an online url as a source. stated in (P248) make a mess the source in wikipedia articles. Plus now it shows both the sources. Moreover, the census item can not have many properties that need as a property. For example, archive URL (P1065). I know that this is wikipedia problem, not wikidata. But, do we really want to have both sources? reference URL (P854) and stated in (P248) for the same statement? I am confused. Xaris333 (talk) 00:22, 3 January 2018 (UTC) Can I use stated in (P248) and reference URL (P854) to the same source? [2] Xaris333 (talk) 22:12, 3 January 2018 (UTC) I do that frequently. Example at League of Cognac (Q47014250). - PKM (talk) 00:31, 4 January 2018 (UTC) Great. Thanks. I though we had to create two different sources. Xaris333 (talk) 02:26, 4 January 2018 (UTC) Constraints about villages I am trying to add statements about a village but some constrains are not clear to me. Ayios Therapon (Q4831306)1) head of government (P6) \"value requires statement constraint. Christodoulos Milonas should have a statement position held (P39).\" That means I have to create an item like \"Ayios Therapon President of Communal Council\" and add it to the person item? A lot of work, maybe useless for small villages.2) executive body (P208) --> Municipal Councilor in Huy (Q29385989)\"distinct values constraint This property's value must not be present on any other item, but is also present on the following items:...\"That means I have to create an item like \"Ayios Therapon Communal Council\" and add this item to the property? \"Ayios Therapon Communal Council\" -->instance of (P31) --> Municipal Councilor in Huy (Q29385989). A lot of work, maybe useless for small villages.Xaris333 (talk) 12:52, 3 January 2018 (UTC) Not necessarily - you can use the property of (P642) as a qualifier, like it is done for the bishop Marc-Antoine Berdolet (Q152944). Then only thing needed for your village heads would be a generic item \"President of Communal Council\". Ahoerstemeier (talk) 00:09, 4 January 2018 (UTC) Thanks. That solves the first problem. But not the second one. Xaris333 (talk) 02:25, 4 January 2018 (UTC) Interlanguage links with anchors and redirects According to Help:Sitelinks#Interlanguage links with anchors I guessed it is not allowed here to add interlanguage links with anchors, but what about redirects? There are already a lot of added here, so one can do this or one should avoid it? See for instance de-wiki links on Q43304118 or Q29924639. Florentyna (talk) 17:15, 3 January 2018 (UTC) Such links are not allowed yet but if you change an already connected page to a redirect, nothing changes in Wikidata (unless you do cleanup). So the item should be treated as if there was no link (the link can be eventually removed and the item may even get deleted). See also Wikidata:Requests for comment/Allow the creation of links to redirects in Wikidata. Matƒõj Such√°nek (talk) 17:47, 3 January 2018 (UTC) As far as I understand the notability policy, it says that redirect don't create automatically notability but not that they \"shouldn't\" or \"mustn't\" be created. The current majority community opinion as shown in the open RfC suggests that the community believes links to redirects are a good idea. If you currently want to create a redirect you have to first create the page as a non-redicrect page. Then you come to Wikidata and add it as sidelinks and then you change the page to be a redirect. On the other hand, you can't simply set a sitelink to a redirect page. ChristianKl ‚ù™‚úâ‚ù´ 02:15, 4 January 2018 (UTC) Renaming a maintenance category Posted by Niridya on the French Project chat in English. I copy here his message. Tubezlob (üôã) 21:15, 3 January 2018 (UTC)Hello everyone,I think it should be a great idea to rename the category Category:Wikidata:Deletion to Category:Candidates for speedy deletion because it will be the same name than in others english Wikis.I post this message because I done it today but my modifications was deleted and the wikipedian said me to reach an administrator consensus.Cordially. I don't think our Wikidata category equals what counts as Candidates for speedy deletion on EnWiki and see no good reason for renaming it. ChristianKl ‚ù™‚úâ‚ù´ 21:41, 3 January 2018 (UTC) Hi, the reason I see is to harmonize names between all English-speaking wikis. --Niridya (talk) 22:02, 3 January 2018 (UTC) BTW Wikidata:Bistro is meant for the French-speaking, not the English-speaking. --- Jura 22:08, 3 January 2018 (UTC) Given that the deletion system isn't the same there's no good reason for it having the same name. ChristianKl ‚ù™‚úâ‚ù´ 01:54, 4 January 2018 (UTC) Change on the editing interface: save becomes publish Hello all,Following the change that have been happening since 2016 on all the wikis of the Wikimedia movement, the ‚Äúsave‚Äù button will be replaced by ‚Äúpublish‚Äù on Wikidata.The main reason for this change is to avoid confusion for new editors, who need to be clearly aware that what they add on the wiki is immediately published online. (more information here).On Wikidata, this will mainly have an impact on the editing interface of the items (blue link next to the field one's currently editing). On any other page like the project pages, discussion pages, etc. the button has already been changed to ‚Äúpublish changes‚Äù.The change will be deployed on January 3rd. In the meantime, you can try it on Beta.If you speak another language than English, please consider helping translating in your language. You can find the translations here and here (change the language code at the end of the URL to find or add a language).Once the change is made, the documentation will need to be updated. Feel free to help updating the screenshots and other mentions of the former ‚Äúsave‚Äù link.Thanks a lot for your understanding, Lea Lacroix (WMDE) (talk) 20:05, 28 December 2017 (UTC) Edit: it's now done. Please let us know it anything displays wrong on your side. Lea Lacroix (WMDE) (talk) 11:56, 4 January 2018 (UTC) Is it worth contributing to pywikibot? I considered submitting a patch for pywikibot, but digging in the source code confirmed by concerns about the state of this project, to the point that I am not even sure it is worth trying to fix anything there. I have summarized my concerns in my userspace, if anybody is interested in that. I think WikidataIntegrator is more promising and I encourage people to use and contribute to that instead. It is still a young library but at least the foundations look saner. Any thoughts? ‚àí Pintoch (talk) 14:45, 29 December 2017 (UTC) @Pintoch: I've used both pywikibot and WikidataIntegrator; the latter was definitely much more in line with what I expected a python library to do, as you outline. I've also attempted to contribute code to pywikibot and ran into trouble getting their tests to run. The data model has problems handling floating point and other special data types correctly relative to what wikidata expects - I was trying to fix that. But I'm sure there are users who do a lot with it, it does generally sort of work. I think it may be trying to do too much to handle both wikidata structure and normal wikipedia pages, which is where the problems stem from. ArthurPSmith (talk) 17:09, 29 December 2017 (UTC) @Pintoch: I've been using and contributing to Pywikibot for over 10 years now. It's a collection of scripts to do things and a library. It's used and written by people who want to scratch an itch. The old version (the now gone compat version) was still using screen scraping. The current version (core) is API based. The switch between the two and the double effort was a huge burden on the developer community. After that was over, some people thought it was cool to have a pypi version. We ended up with two branches again and nobody maintaining the Pypi branch so we killed it and switched it to release every once in a while releasing when all tests are green. I'm not happy with the pypi situation at all. I don't think anyone is actively maintaining it right now. I've never actually used it myself. I always use the git version and tell other people to do the same. I've seen many times people coming up with big plans to split up Pywikibot, to rewrite it or just generally complaining. In the end it was usually just a waste of time that could have been spent much better on improving what we have. So yes, contributions are very much appreciated. If you run into things, file tasks in Phabricator and tag pywikibot-wikidata. Please do contribute code. Small easy to digest patches work best. Also code review could use a hand. This all helps the many people running Pywikibot. Multichill (talk) 14:37, 30 December 2017 (UTC) @Multichill: I don't dispute the value of pywikibot for many people, but I am questioning its usefulness as a Python library. What I personally need is a Python library to interact with Wikibase. I tried to explain in my note why pywikibot really isn't a satisfactory library yet, and why I think it would be a lot of effort to transform it into a proper library. It's fine to build things that are not libraries - but they should not be advertised as such, because then people invest time into it before they realize they cannot use it for what they need. I feel bad about complaining without proposing any patch - but that is because after investing a lot of time working with pywikibot (both for Wikipedia and Wikidata), I have just given up: the foundations are broken beyond repair as far as I can tell. Maybe it's just a cultural issue - the Wikimedia community does not use Python much and does not value the standards from the Python world. In that case, that's obviously fine - take my rant as an explanation of why these two communities differ and why you are losing contributors who have the same sort of expectations as I have. ‚àí Pintoch (talk) 09:03, 31 December 2017 (UTC) Pywikibot is not only Wikidata, unlike WikidataIntegrator. It can work with multiple wikis at once (eg. Wikidata, Wikipedia and Commons). Matƒõj Such√°nek (talk) 14:53, 30 December 2017 (UTC) Sure - it would be great to have a Python library for the MediaWiki API in general, not just for Wikibase. ‚àí Pintoch (talk) 09:03, 31 December 2017 (UTC) What do you think would be needed to have WikidataIntegrator do what you want? ChristianKl ‚ù™‚úâ‚ù´ 00:56, 2 January 2018 (UTC) @ChristianKl, Pintoch: As the \"inventor\" and one of the main developers of Wikidataintegrator, the intention always was to create something which resembles a database driver for Wikibase/Wikidata which integrates the API and the SPARQL endpoint, ignoring most of the other parts of the MediaWiki framework API, so if there are useful features, just let me know about them, we will see if how/these can be implemented, or just submit a pull request. Sebotic (talk) 10:25, 4 January 2018 (UTC) @Sebotic, ChristianKl: I have only used WikidataIntegrator a few times so I am not very familiar with it yet. From what I have seen, the library tries to provide a convenient high-level interface, but I am not sure all concepts of the Wikibase data model are accurately represented. It looks like users are expected to manipulate dictionary-based representations directly - I have not seen any classes for the various concepts of the data model, for instance (like statements, qualifiers or references). I think a more object-oriented architecture would be nice. Something like WikidataToolkit for Python would be ideal. ‚àí Pintoch (talk) 11:45, 4 January 2018 (UTC) I've added a reply at User talk:Pintoch/Issues with pywikibot. John Vandenberg (talk) 16:31, 2 January 2018 (UTC) Thanks, I have replied there too. ‚àí Pintoch (talk) 11:45, 4 January 2018 (UTC) How to improve the usefulness of Wikidata descriptions? The latest discussion about disabling showing Wikidata descriptions alongside enwp content is going on at en:Wikipedia:Village_pump_(proposals)#RfC:_Populating_article_descriptions_magic_word. I'm mentioning this not to encourage people to !vote in it, but because there's an interesting discussion there about a sample of 10k descriptions that @DannyH (WMF): assembled. In particular there are concerns about the usefulness of the descriptions (there's also a ranking going on with a sample of 1k descriptions at en:User talk:Pbsouthwood/Wikidata description Quality Assessment experiment), and concerns about how long vandalism takes to be reverted here. I'd encourage reading through the comments posted there.Any ideas how we can fix these problems here? I've been looking into using Huggle here, but it doesn't seem to work (phab:T183141) - are there other anti-vandalism tools? (m:2017 Community Wishlist Survey/Wikidata/Better countervandalism tools didn't make it into the top 10 sadly.) Or are there ways we could systematically (usefully) improve the descriptions? Thanks. Mike Peel (talk) 07:19, 30 December 2017 (UTC) I am still not convinced that we have a problem with Wikidata descriptions at all. They work as desired (disambiguation of items with identical labels) and they are intentionally very short, thus I do not agree with the rating scheme invented on the page of User:Pbsouthwood. Display of Wikidata descriptions in mobile apps and search fields was invented later and one can of course question whether the descriptions as they are used inside Wikidata are useful for that task as well. Personally I think that it is a no-brainer to find that they are, but I understand that others may have a different opinion. On vandalism: filtering the RC stream to patrol changes is indeed an important problem, and we would be happy if more editors were engaged in counter-vandalism activities. There are some tools which provide filter options, such as Pasleim‚Äôs reCh tool (login, then filter for terms and \"en\" language code) or User:Yair rand/DiffLists.js; the ORES markers for potentially critical edits are useful as well. RC editors are also encouraged apply for the rollback right to work efficiently. ‚ÄîMisterSynergy (talk) 07:55, 30 December 2017 (UTC) See https://www.wikidata.org/wiki/Wikidata:WikiProject_Counter-Vandalism for more about our counter-vandalism efforts. ChristianKl ‚ù™‚úâ‚ù´ 08:40, 30 December 2017 (UTC) Looks like another car-crash engineered by the anti-Wikidata cabal‚Ñ¢ on en.Wikipedia. That said, one of the issues raised is the discussion is that of Wikidata editor notes in descriptions (the example given being \"determined sex of an animal or plant. Use Q6581097 for a male human\"). It is in our gift to fix that, and we should do so promptly. Andy Mabbett (Pigsonthewing); Talk to Andy; Andy's edits 09:23, 30 December 2017 (UTC) There was a separate property for usage notes (Wikidata usage instructions (P2559)), but since they aren't shown when you want to add information on Wikidata, there currently is no other option than to use the descriptions. Mbch331 (talk) 12:05, 30 December 2017 (UTC) The example in question can be easily fixed by merging male (Q6581097) as I proposed on the talk page with is very benefitial for other concerns as well. ChristianKl ‚ù™‚úâ‚ù´ 14:09, 30 December 2017 (UTC) There are many other examples of Wikidata-specific instructions in descriptions. Andy Mabbett (Pigsonthewing); Talk to Andy; Andy's edits 13:37, 4 January 2018 (UTC) Monuments list of monuments (P1456) link to the list of heritage monuments in the place/area. If a place has only one monument? We can't have a list. Xaris333 (talk) 22:43, 3 January 2018 (UTC) Why not? I had such list in Latvian WLM lists. --Voll (talk) 08:49, 4 January 2018 (UTC) We can have lists out of one monument, no problem.--Ymblanter (talk) 15:40, 4 January 2018 (UTC) Format of Polish cultural heritage register number (P3424): reference in a Polish cultural heritage register Please comment at Property talk:P3424. --- Jura 13:30, 4 January 2018 (UTC)  Format of LAU (P782): identifier for a local administrative unit, renamed from NUTS 4 and NUTS 5. Format: 2 letters followed by digits Please comment at Property talk:P782. --- Jura 13:30, 4 January 2018 (UTC) Geocodes of Cyprus In Cyprus, the CYSTAT (Q28863790) have statistical codes of municipalities and communities constitute a 4-digit coding system. It called them geographical codes (geocodes). They are national codes. Should I propose a new property for these code or there is another way to add the data to wikidata? Xaris333 (talk) 00:31, 4 January 2018 (UTC) 4-digit system, that is 10,000 possible identifiers? If the identifier is truly an \"identifier\" (unique etc.), I suggest going ahead. Matƒõj Such√°nek (talk) 07:35, 5 January 2018 (UTC) Yes, they are unique. 4-digit system (only for quarters are 6-digit numbers). See Wikidata:Property proposal/Statistical Service of Cyprus Geocode. Xaris333 (talk) 07:44, 5 January 2018 (UTC) Signs displaying the name of a place where they are not situated Can anyone answer Property talk:P1766#Signs displaying the name of a place where they are not situated? Xaris333 (talk) 02:50, 5 January 2018 (UTC) Inconsistencies between Q937130, Q3540821, and Q788723 Dear Wikidata users,Being not used to modify Wikidata, i need your help to correct the inconsistencies observed between Q937130, Q3540821 and Q788723. They all refer to articles related to the Tibesti Mountains.Q937130 refers in 3 languages to the place called Trou au Natron, but redirect in French to the place called Tarso Toussid√©. We have in French an article called Trou au Natron, but it is associated with Q3540821 (where French is the only language).We have in English an article called Tarso Toussid√©, associated to Q788723, which refers in most languages to the highest point of this massif, the Pic Toussid√©. By consequence, I suggest: to associate Q937130 only with the term Trou au Natron, remove the incorrect French link, and replace it with the single link from Q3540821 discard by consequence Q3540821 which becomes unused have Q788723 only related to the Tarso Toussid√© (largest massif) create a new object only related to the articles referring exactly to the Pic Toussid√© (the highest point of the Tarso Toussid√©). What do you think of these suggestions?I thank you for your help --Ndiver (talk) 11:57, 5 January 2018 (UTC) @Ndiver: Sounds good. Q937130: the statements on this item seem to be about \"Trou au Natron\". Maybe instance of (P31) needs a better value, but coordinates and elevation seem ok. So I agree with you. From a Wikidata point of view, it's important that the sitelinks are added to the item that has the correct statements. Q3540821 can be merged into Q937130, once the frwiki sitelink deleted from Q937130. If you know other features of these massifs, you might want to create items for them as well. It's not required that there are Wikipedia articles about these. Thanks for spotting the problem and suggesting a solution. --- Jura 22:04, 5 January 2018 (UTC) Civil Rights Memorial The article for the Civil Rights Memorial mentions the people named on the memorial and the \"forgotten\" where the documentation of their death was not fully documented at that time. How do I model this? Thanks, GerardM (talk) 14:31, 6 January 2018 (UTC) Maybe, as a starting bid ‚ü®‚ÄØThe Forgotten‚ÄØ‚ü© subclass of (P279) ‚ü®‚ÄØgroup of humans (Q16334295) ‚ÄØ ‚ÄØ‚ü© manner of death (P1196) ‚ü®‚ÄØkilled in struggle‚ÄØ‚ü© significant event (P793) ‚ü®‚ÄØcivil rights movement (Q13406660) ‚ÄØ ‚ÄØ‚ü© and ‚ü®‚ÄØkilled in struggle‚ÄØ‚ü© subclass of (P279) ‚ü®‚ÄØmanner of death (Q2438541) ‚ÄØ ‚ÄØ‚ü© ? --Tagishsimon (talk) 17:43, 6 January 2018 (UTC) Worldcat Identities Would it be a good idea to make a property/identifier \"WorldCat Identity\", linking to the OCLC/WorldCat Identities like e.g. Charles Henry Hull with identity http://worldcat.org/identities/lccn-n85377312/The WorldCat Identities contain a lot (but not all writers) that have texts in WorldCat with overviews of publications etc.This is really an important authority control. See: w:en:Help:Authority_control.I have no idea how to do this, but perhaps someone can create this new property/identifier.... --Dick Bos (talk) 15:06, 6 January 2018 (UTC) In this case WorldCat says \"lccn-n85377312\". That means the person with the Library of Congress authority ID (P244) \"n85377312\". ChristianKl ‚ù™‚úâ‚ù´ 16:40, 6 January 2018 (UTC) On the English Wikipedia, they use the VIAF identifier to link to Worldcat .. Thanks, GerardM (talk) 17:53, 6 January 2018 (UTC) Produced sound I didn't notice it during the property proposal discussion, but it seem to me that the new produced sound (P4733) is redundant to audio (P51) - if not, many (but not all!) values will have to be moved from the latter to the former. Andy Mabbett (Pigsonthewing); Talk to Andy; Andy's edits 19:22, 12 January 2018 (UTC) @Thierry Caro, ÿØŸäŸÅŸäÿØ ÿπÿßÿØŸÑ ŸàŸáÿ®ÿ© ÿÆŸÑŸäŸÑ 2, Jsamwrites, ChristianKl, ArthurPSmith: from the proposal discussion. Andy Mabbett (Pigsonthewing); Talk to Andy; Andy's edits 19:23, 12 January 2018 (UTC) The new property has the item datatype, while the other one has the Commons file one. How can it be redundant then? \"produced sound\" is to link to the item describing the sound something makes. Sjoerd de Bruin (talk) 19:25, 12 January 2018 (UTC) @Pigsonthewing: audio (P51) is Wikidata property to link to Commons (Q18610173) and the data type is different.Thank you David (talk) 20:05, 12 January 2018 (UTC) Ah, sorry, I missed that. Andy Mabbett (Pigsonthewing); Talk to Andy; Andy's edits 20:27, 12 January 2018 (UTC) This section was archived on a request by: Andy Mabbett (Pigsonthewing); Talk to Andy; Andy's edits 20:27, 12 January 2018 (UTC) Free image available at url property? Hi everyone, for the Sum of all paintings I add and update a lot of items about paintings on Wikidata. Often these paintings don't have an image available on Commons, but do have a free image available on the source website. Uploading these images is currently not part of my workflow and I don't have any plans to add it, but I would like to do something with this data.What I'm thinking of is a new property (of type URL) \"free image available at url\" in which we can store the direct link to the out of copyright work that can be uploaded to Commons. As qualifiers some data can be stored that would be needed on Commons to properly upload the image. For example for Red Sail in the Harbor at Venice (Q46924693): The new property -> [3], qualified with: described at URL (P973) -> http://www.cincinnatiartmuseum.org/art/explore-the-collection?id=17993350 title (P1476) -> \"Red Sail in the Harbor at Venice \" author name string (P2093) -> \"Frank Duveneck (American, b.1848, d.1919), painter\" (exact properties to use here open for suggestions and improvements)This data combined with the data already on the item should be enough for a (semi-)automatic tool to upload these images to Commons. The tool should: grab the data from the Wikidata item do some checking (to prevent non-free works from slipping through) upload it to Commons using the artwork template with a linkback to Wikidata. update the Wikidata item with the new image and remove the \"free image available at url\" property Currently we have 234.162 painting items of which (only) 70.696 are illustrated. I think we can get at least double that using this approach. What do you think? Multichill (talk) 15:43, 26 December 2017 (UTC) Yes that would be great to have. Especially if you have the url at hand but no time for the upload (yet). Jane023 (talk) 21:16, 26 December 2017 (UTC) WikiProject sum of all paintings has more than 50 participants and couldn't be pinged. Please post on the WikiProject's talk page instead. some more input would be nice. Multichill (talk) 21:27, 27 December 2017 (UTC) This is also useful for works not out of copyright but with a public domain date (P3893) in the near future for semi-automatic uploading to Commons once date has been reached. I would propose we don't call it 'free' as it is not clear what that will mean. I would also propose to have a property with the .jpg file (or even the zoom file (.dzi or ImageProperties.xml etc) as to have the direct download of the image available. In your example: http://collections.cincinnatiartmuseum.org/pictiondmz/ump.di?e=4C36D94713293518451249F6419DF088AFA28295C9C09B27F1430AACF2815D73&s=21&se=149022812&f=%5Cd9335%5Cu17993350%5C1915.135_v01_o4.jpg --Hannolans (talk) 21:42, 27 December 2017 (UTC) Thanks for your reply Hanno, As for soon in copyright. That would make it impossible for someone to clean it out. Some statements can't be fixed. And what is soon? 1 year? 1 century? How would you propose to call it? You just said you didn't like the 'free' part, but you didn't propose an alternative My link was to the direct download, but it's just a crappy website with multiple options in this case so both links seem to return the same jpeg file. Multichill (talk) 16:59, 28 December 2017 (UTC) Good idea! --Marsupium (talk) 12:01, 29 December 2017 (UTC) Support - PKM (talk) 20:09, 29 December 2017 (UTC) ' Support' - But it needs clarification of what is meant by 'free'. Maybe 'openly-licenced image available' would be more accurate. Xcia0069 (talk) 09:58, 2 January 2018 (UTC) It would make sense to make a proper property proposal for this to have further discussion. ChristianKl ‚ù™‚úâ‚ù´ 01:10, 1 January 2018 (UTC) That was of course the plan, but I first wanted people the time to comment on this. The proposal is now at Wikidata:Property proposal/Commons compatible image available at URL. Let's continue over there. Multichill (talk) 11:44, 7 January 2018 (UTC) Area precision Tracked in Phabricator Task T155910 How serious we are to take the data like this [4]? Shoudn't this be just six? Courtesy pinging @MB-one:--Ymblanter (talk) 16:58, 6 January 2018 (UTC) Or at least 5,99. --Edgars2007 (talk) 17:01, 6 January 2018 (UTC) The value, that was entered from the source was in this case 5.99 km¬≤. These values are a result of this issue with QuickStatement. While the seemingly random addition or subtraction from the entered value is certainly annoying, it doesn't create any problem here, because the deviation in the result is several orders of magnitude smaller, than the accuracy of the value itself. --MB-one (talk) 17:21, 6 January 2018 (UTC) Thanks. Hopefully it will be fixed at some point, either from the QuickStatement end or from our end.--Ymblanter (talk) 21:09, 6 January 2018 (UTC) I haven't been successful with my fix... Matƒõj Such√°nek (talk) 09:25, 7 January 2018 (UTC) Time to split Wikidata:List_of_properties/Terms The page displays lua overflow error messages - it's just too long and needs a careful split. Apologies for writing here - the issue was raised on appropriate talk page half a year ago, nothing happened. Retired electrician (talk) 19:08, 6 January 2018 (UTC) Wikidata:List of properties/all, too. Perhaps these lists can be generated as static text, rather than live lua calls? Retired electrician (talk) 19:10, 6 January 2018 (UTC) If you want to edit the page feel free to go ahead. ChristianKl ‚ù™‚úâ‚ù´ 19:32, 6 January 2018 (UTC) A static version of Wikidata:List of properties/all exists at Wikidata:Database reports/List of properties/all --Pasleim (talk) 20:21, 6 January 2018 (UTC) Intercardinal direction items - constraint If an item Y has a property (for example shares border with (P47)) with value item X with direction relative to location (P654)-->south (Q667), then shouldn't item X has the same property with value item Y with direction relative to location (P654)-->north (Q659)? Is that an appropriate constraint? If yes, I don't know how to do it. :)However, on intercardinal direction (Q15410629) items there are more than one value to opposite of (P461) with opposite direction (Q21012911), orthogonal direction to the left (Q22672535) and orthogonal direction to the right (Q22672531). Can we have the constraint only if the qualifiers is using with shares border with (P47) or other specific properties?Cases (for shares border with (P47): south (Q667) - north (Q659) east (Q684) - west (Q679) northeast (Q6497686) - southwest (Q2381698) northwest (Q5491373) - southeast (Q6452640) Xaris333 (talk) 07:03, 7 January 2018 (UTC) We can use {{Complex constraint}} and also generate statements with missing qualifiers for QuickStatements. Matƒõj Such√°nek (talk) 09:21, 7 January 2018 (UTC) Not necessarily true. For instance, Netherland is on the Northwestern side of Germany, however Germany is on the weastern side instead of southeastern side of Netherland. C933103 (talk) 09:27, 7 January 2018 (UTC) Ok. I understood. It's now always true. So we can do nothing? Xaris333 (talk) 14:36, 7 January 2018 (UTC) How does Wikidata handle projected data? Hi allIs there any information or any examples of how Wikidata handles projected data? Some projected data forms the basis of large decision e.g project sea level rises by a certain date or projected temperature increases by increased atmospheric CO2. It seems incredibly important to have this data in Wikidata especially in relation to Wikidata fed maps and charts on other Wikimedia projects.Some thing to consider may be: There may be several projections by different groups or studies eg projected extinctions of species due to overfishing or habitat destruction The same organisation may have changed or updated their predictions over time as the situation changes or modelling improves eg actual and projected ozone layer depletion by a certain date before CFC bans came into place Thanks--John Cummings (talk) 10:33, 7 January 2018 (UTC) My first instinct would be to use sourcing circumstances (P1480) as a qualifier but I don't know whether there's an existing way to do this. ChristianKl ‚ù™‚úâ‚ù´ 12:22, 7 January 2018 (UTC) Idiot's guide to add interwiki link? Tracked in Phabricator Task T163713 I edit Wikipedia for more than decade. Links to other language articles were always part of the article text. Never had any problem with it. But now I am thrown inside wikidata project, into some web form and here I fail. I simply do not know what to do, where to click. Nothing seems to work (in Chrome).Is there guide for a complete idiot, how to add interwiki (and nothing else)? I tried to look it up but failed too. 85.70.87.168 18:32, 4 January 2018 (UTC)Specifically I tried to connect this page: https://cs.wikipedia.org/wiki/Kronika_troj√°nsk√° with https://en.wikipedia.org/wiki/Historia_destructionis_Troiae On Czech wiki the interwiki web form is different (much simpler) but it gave me error message: \"Chyba: $1. Attempted modification of the item failed.\"85.70.87.168 18:48, 4 January 2018 (UTC) The en. article is linked to Historia destructionis Troiae (Q1241142). The cs article is linked to Kronika troj√°nsk√° (Q12031574). Those two wikidata records need to be merged. (However, for reasons not clear to me, they're currently refusing to merge.) --Tagishsimon (talk) 18:53, 4 January 2018 (UTC) Duly reported --Tagishsimon (talk) 18:56, 4 January 2018 (UTC) Kronika troj√°nsk√° (Q12031574) has edition or translation of (P629) Historia destructionis Troiae (Q1241142), that's why they cannot be merged.--Ssola (talk) 23:17, 4 January 2018 (UTC) I've added an English label and description to Kronika troj√°nsk√° (Q12031574). It looks like the cs article is specifically about the 15th-century Old Czech translation. Wikidata is more granular than Wikipedia. In Wikidata, a Latin work and a translation of it are two separate things. - PKM (talk) 02:49, 5 January 2018 (UTC) They should be interwikilinked, and that is, what Wikidata is supposed to deliver. An article about Harry Potter in any given language will use the names in that language instead of the original ones, and only give the original ones as another information, but nevertheless all those articles should be interwikilinked. Wikidata has to deliver such stuff, it's the main purpose of wikidata to organise this in a manner wanted by the other projects, where WD is used as a database. So how are those articles, that are about the same item (sometimes in different translations) be interwikilinked? And if Wikidata doesn't deliver such basic needs, the stuff it was build for after all, any longer, where to organize this outside Wikidata? S√§nger (talk) 08:24, 5 January 2018 (UTC) 15th century is two centuries after 13th century. If you think it's the same for cswiki, you could use local interwiki links. --- Jura 08:35, 5 January 2018 (UTC) 1997 is not 1998, so why is de:Harry Potter und der Stein der Weisen interwikilinked with en:Harry Potter and the Philosopher's Stone? S√§nger (talk) 11:11, 5 January 2018 (UTC) The translation of a work two centuries after the original version are inter-related though different concepts. The translation has a translator, which the original does not, the language is different; the editing is different, etc. One could put forward a case that for the Harry Potter works should be different, though there is a lot more commonality and central control to these works. Personally, I would have them as separate items, though I am a separationalist when it comes to works and their translations. ‚Äî billinghurst sDrewth 12:09, 5 January 2018 (UTC) So what is your suggestion for the interwikilinking of this articles? How should this be done in Wikidata, the tool used for interwikilinking in the wikiverse? How could this main purpose of wikidata, besides storing data about relevant items from the wikiverse, be solved in a way usable by the main clients of this database, the different language versions of the wikipedia? S√§nger (talk) 12:14, 5 January 2018 (UTC) Hopefully sooner or later the RfC for redirects will be resolved and we will have that tool for providing links in cases like this. Currently, it seems it isn't resolved because WMDE doesn't give feedback. I added https://www.wikidata.org/wiki/Wikidata:Contact_the_development_team#WMDE_feedback_for_the_RfC_%22Allow_the_creation_of_links_to_redirects_in_Wikidata%22 to ask for feedback. ChristianKl ‚ù™‚úâ‚ù´ 14:07, 5 January 2018 (UTC) @S√§nger: The Wikisources face this issue extensively for interwiki between the Wikisources (edition to edition/translation) and from the Wikisources <-> Wikipedias (edition to creative work/translation). At this time the immediate solution is manual interwikis. The Wikisources are looking at how we utilise the edition or translation of (P629) and has edition or translation (P747) links and using lua scripts to put in place interwikis. The evolution of Wikidata has highlighted that interwikis are a looser relationship than what occurs on an item, so the wikis can continue with manual interwikis for loose relationships or have scripts to work it out; it is not Wikidata's responsibility to do that. I am not in agreement with ChristianKl that redirects are the means to address that, it seems a mongrel of an approach to dupe the system. ‚Äî billinghurst sDrewth 03:20, 6 January 2018 (UTC) @S√§nger, billinghurst: for your information, a @Tpt: is now working on a solution to be able to autolink editions of books to the actual work item from wikisource, and this probably could be usable for wikipedia afterwards. In the meantime, manual interwikilinks, or a specific template can use the edition or translation of (P629) info like the one used by sv wikisource. --Hsarrazin (talk) 07:57, 6 January 2018 (UTC) How could one do manual interwikilinks? I started the discussion and, so far, it gave no answer to my question. I would happily use the traditional method I know. Btw, there's no realistic chance in Czech Wikipedia to have separate article for the original chronicle. Troj√°nsk√° kronika is our oldest (or one of the oldest) incunabulum and all it got is a small shallow article. 85.70.87.168 18:31, 7 January 2018 (UTC) You cannot do 'manual sitelinks', beyond the normal mechanism in wikidata of adding the wikipedia page to the wikipedia section of the item record. The issue in this instance is that wikidata allows a wikipedia page to be added only to a single wikidata item, and your cs article is already linked to a wikidata item. Other language articles about a similar subject are linked to a different wikidata item. So you will not get interwiki links from the cs article until this issue is sorted out. --Tagishsimon (talk) 18:37, 7 January 2018 (UTC) manual interwikis = traditional interwiki links at the source site, here we are talking csWP so [[en:Historia_destructionis_Troiae]] ‚Äî billinghurst sDrewth 06:44, 8 January 2018 (UTC) Film narration in different languages Hi. I've become more active in Wikidata again, as a result of shifting work from enwiki to frwiki. I'm very impressed by how frwiki is now using Wikidata to generate Film Infoboxes. I have one question: do you think it'll ever be useful or practical to assign a language to the \"narrator\" field, sort of like we do with film titles where there's a mandatory language field? Canada is an officially bilingual country (English/French) and films with narration often exist in the two languages, with different people doing the narration. I guess it's true for any non-subtitled film with narration that gets versioned internationally. A good example of this would be the Oscar-nominated short doc Q5123702. As you can see from the respective Eng. and Fr. articles (both of which I worked on) there are two notable voice actors, one for each language. (And different script credits too). But if I add the various names into Wikidata currently, it'll seem like Q606553 and Q3435174 jointly narrated the film -- which they did, but in their respective languages. Hope this makes sense. thanks, Shawn in Montreal (talk) 14:08, 5 January 2018 (UTC) @Shawn in Montreal: The usual way toi treat that kind of case is to create 3 items: one item for the work, one item for the french version and one item for the canadian french version and to link the 2 versions to the work. The work item will contain all data common to all versions of the movies and the other items will contain only the data rlevant to the version they represent. But this system seems to not be compatible with the rules of the Wikidata: WikiProject Movies, so th ebest is to ask the people from that project to answer. Snipre (talk) 19:49, 5 January 2018 (UTC) @Jura1: Please explain the good way to model data for movies. Snipre (talk) 19:49, 5 January 2018 (UTC) @Shawn in Montreal: I've found this in the Wikiproject movies documentation. A separate element for each different adaptations looks like a solution to the problem. -- Peuc (talk) 21:48, 7 January 2018 (UTC) 2017 Chile census The final population data for the 2017 Chile census (Q21001879) are available since December 22 (censo2017.cl, Cantidad de personas por sexo y edad - XLSX format). I manually uploaded the population (P1082) data (but not female population (P1539) and male population (P1540)) for the region of Chile (Q590080) (first-level subdivision). It is necessary to upload the data of the province of Chile (Q1153408) (second-level subdivision) and commune of Chile (Q1840161) (third-level subdivision). Is there a simpler way to load the information than to do it one by one? If it is not possible, could someone help me finish? Thanks you, Metr√≥nomo (talk) 17:59, 7 January 2018 (UTC) QuickStatements can help you. Matƒõj Such√°nek (talk) 18:17, 7 January 2018 (UTC) OK. I tried it but it did not give a good result (or I do not know how to use it correctly). The command Q2118 P1540 315014 P585 +2017-00-00T00:00:00Z/9 P459 Q39825 produced this. The command was correct? How do I add the \"preferred level\"? It is necessary to distinguish it from the old population data. I can not find it in the documentation. --Metr√≥nomo (talk) 18:39, 7 January 2018 (UTC) I forgot that QS still cannot work with ranks... (we have a bot that can rearrange them, though). I prefer having the gender-related population as a qualifier of the statements like this: Q1|P1082|2|P1540|3|P1539|4|P585|+2017-00-00T00:00:00Z/9|P459|Q39825|S248|... (it would be nice to include the source as well). Matƒõj Such√°nek (talk) 18:57, 7 January 2018 (UTC) Rules for linking to WD from WP Does anyone know what the rules are for linking to wikidata when wikipedia does not have a corresponding article. I have noticed people removing the links, But I cannot find the rule they are following. --RAN (talk) 20:02, 7 January 2018 (UTC) Probably depends on the language edition of Wikipedia.--Ymblanter (talk) 21:12, 7 January 2018 (UTC) Dataset on typhoon warning messages issued by authority See [5] and [6].At past, in some articles about typhoon in Chinese Wikipedia, there were a list that includes information about all the trihourly warning issued by Taiwanese meteorology office when a typhoon is affecting Taiwan. These information are now being removed from related articles for various reason. Should these data be included into wikidata? C933103 (talk) 03:02, 7 January 2018 (UTC) How much data points are we talking about per item? ChristianKl ‚ù™‚úâ‚ù´ 12:42, 7 January 2018 (UTC) Usually a few dozens data point? The one I linked have 14 entry. Each entry include issued time, serial number, advisory/alert type, cyclone center position, radius for Beaufort scale 7 wind, max wind speed near center, max instantious wind speed, predicted position 24 hours after the issued bullet, and also the area covered by the warning/advisory. C933103 (talk) 13:24, 8 January 2018 (UTC) The Giant Turnip (Q2068935) In most languages wikipedia version, the wikidata entry is about the original Russian folklore story. However, in Israel, the linked article is about the Israeli adaption of the story. Many of the descriptor for the wikidata item was also about the Israeli adaption instead of the original work, like the claim that the wikidata item subect was originally written in Hebrew. These claims have been removed, but should the hebrew song get separated into a different wikidata item which would contain those specific details that only applies to the Israeli adaption? While doing so would have the advantage of clearly separating the two entries, it would also mean that it would be impossible to interlink between the Hebrew version article and the English version article. Also, there is a Chinese article regarding the Chinese version adaption of the story but it is not linked in the wikidata item here and thus readers are not able to use interwiki link to navigate between different languages. How to fix that?C933103 (talk) 08:57, 7 January 2018 (UTC) We need separate items here to be as accurate as possible. For wikis it is still possible to use \"old-style\" interwiki to connect pages from another item.--Jklamo (talk) 17:18, 7 January 2018 (UTC) Are those old interwiki bots still functioning in this aspect?C933103 (talk) 13:17, 8 January 2018 (UTC) Books and articles What's the current consensus on creating wikidata records for books and articles that are used as sources in wikipedia articles? Say, The Dolby Era: Film Sound in Contemporary Hollywood (Q29384930). These works don't have corresponding articles about them, and most of them never will. Reading Wikidata:Notability and Wikidata:What Wikidata is not together suggests that the answer is no - ?? Retired electrician (talk) 18:43, 6 January 2018 (UTC) A somewhat related question: is there a way to check usage of Q29384930 in wikipedia(s)? Retired electrician (talk) 18:43, 6 January 2018 (UTC) See Page information of Q29384930, section ‚ÄúPage properties‚Äù. If you click on the ruwiki link, you‚Äôll find the ruwiki page that uses that item. ‚ÄîMisterSynergy (talk) 18:51, 6 January 2018 (UTC) Books are generally clearly defined conceptual entities that can be described with serious sources and are thus notable under that passage. WorldCat and Google books are both such kind of sources. ChristianKl ‚ù™‚úâ‚ù´ 22:58, 6 January 2018 (UTC) @Retired electrician: There are currently many articles that have their items where the published books or journals have existing items. For example, all the articles from the 63 volumes of Dictionary of National Biography, 1885‚Äì1900 (Q15987216) have their own WD item, and interwiki link to Wikisource, and to their respective main subject items. If adding an article you would generally have: instance of (P31) article or biographical article or news article, etc.; published in (P1433) \"work name\" of book/journal, with qualifiers of things like ... volume, issue, pages, publication date; main subject (P921); then either author (P50) or author name string (P2093); you might have other components, but these are the main that I have used. At the main subject you would have described by source (P1343)} \"work name\" of book/journal, and qualified with statement is subject of (P805) pointing to the item on the article. ‚Äî billinghurst sDrewth 11:43, 7 January 2018 (UTC) @Retired electrician: See also Wikidata: WikiProject Books, Wikidata:WikiProject Source MetaData, and m:WikiCite. Andy Mabbett (Pigsonthewing); Talk to Andy; Andy's edits 20:30, 8 January 2018 (UTC) Wikidata weekly summary #294 Here's your quick overview of what has been happening around Wikidata over the last week. Discussions Open request for adminship: Jarekt New request for comments: Changes to P2737 and P2738, Privacy and Living People Events/Press/Blogs Upcoming: IRC office hour on January 30th - you can share ideas for topics to discuss Call for papers for WikiIndaba is open Scholarship applications for Wikimania are open Registration is open for the Wikimedia hackathon Paper submission deadline for Wiki Workshop (part of The Web Conference) is closing later this month The Tom Longboat Awards as Wikidata - Mita Williams Using the Semantic Web to Improve Knowledge of Translations - Karen Smith-Yoshimura (OCLC) There is no deadline so every second is one: on anxiety, perfectionism, and Wikimedia projects by L√©na Up2date software versions for Wikidata by Michi Other Noteworthy Stuff Wikidata will be in read-only mode on January 9th from 06:00 to 06:30 UTC The WikidataCon 2017 report has been published Results of two research projects for Structured Data on Wikimedia Commons have just been published: Supporting Commons contributions by GLAM institutions: an overview of how cultural institutions contribute to Wikimedia Commons, and which issues they encounter there Baseline Metrics for Structured Data on Wikimedia Commons: an overview of measurable behaviors on Wikimedia Commons, against which the effectiveness of structured data can be measured in the future You can start organizing an event for Wikidata's 6th birthday in October 2018 A short summary of the workshop with historians using Wikibase to collect data about the Illuminati has been published at Wikidata:FactGrid How would the World look like if countries were as large as their Wikidata items are used across the Wikimedia projects? New catalogs in Mix'n'match - for example Rolling Stone artist New tool: Hub Did you know? Newest properties: MuBE Virtual ID, Basketball-Reference.com WNBA coach ID, Basketball-Reference.com NBA coach ID, Acad√©mie fran√ßaise member ID, Acad√©mie des Inscriptions et Belles-Lettres member ID, Guide to North American Birds ID, title page number, Walters Art Museum ID, Minneapolis Institute of Art artwork ID, CHGIS ID, Guardiana ID, Barnes Foundation ID, VOGRIPA ID, Rugby Canada ID, Ent'revues ID, World of Spectrum ID, Smithsonian American Art Museum ID Query examples: Events starting in 2017 and ending in 2018, shortest duration first (source) Newest database reports: days of 2018 Development Tweaked the ranking of the results in the entity suggester Finished persistently storing edits of statements on forms (phabricator:T163724) Cleaned up some of the hard-coded demo data on the demo system for lexicographical data Working on diff support for Forms on Lexemes (phabricator:T182424) Prevented checking of constraints on \"Wikidata property example\" statements (phabricator:T183267) Added link to the property's talk page to the constraint violation dialog to guide people there to discuss the constraint if necessary (phabricator:T164351) Monthly Tasks Add labels, in your own language(s), for the new properties listed above. Comment on property proposals: all open proposals Suggested and open tasks! Contribute to a Showcase item. Help translate or proofread the interface and documentation pages, in your own language! Help merge identical items across Wikimedia projects. Help write the next summary! Read the full report ¬∑ Unsubscribe ¬∑ Lydia Pintscher (WMDE) 20:34, 8 January 2018 (UTC) Recoin now available as gadget Dear community,I am glad to announce that Recoin is now available as gadget. Recoin adds a status indicator to entities which quantifies the extend of information (completeness) relative to other entities of same profession or type. Furthermore, it shows the top 5 absent properties of an entity at the top of the page.Arno Kompatscher: Politician missing basic information Looking forward to your comments!Cheers, Ls1g (talk) 19:56, 2 January 2018 (UTC) That's excellent, Lsig. But would be more useful if the list produced could be used directly to enter into the addition of a missing property. --Tagishsimon (talk) 20:48, 2 January 2018 (UTC) Good. Where can we translate it? Xaris333 (talk) 00:13, 3 January 2018 (UTC) @Xaris333: Thanks for the suggestion! We are working on multilinguality and will push the changes soon. Property labels will be translated automatically, few other strings need to be manually translated here. Preview see picture on the right. Ls1g (talk) 16:18, 9 January 2018 (UTC) Preview of multilingual version of Recoin excellent Ls1g !! a very useful feature would be a button or link to directly add the wanted property :) --Hsarrazin (talk) 12:59, 7 January 2018 (UTC) @Tagishsimon, Hsarrazin: Looking into this now! Ls1g (talk) 16:23, 9 January 2018 (UTC) Good work, @Ls1g:; thank you very much. Let's have Recoin on steroids. You might take a look at https://www.wikidata.org/wiki/Wikidata:Project_chat/Archive/2017/12#New_userscript_quickpresets which is a different thing; but presumably Recoin could drive a presentation a little like this for the missing statements? And thank for for Recoin even as it is; it's a very useful UI addition. --Tagishsimon (talk) 17:53, 9 January 2018 (UTC) toclimit Are the CSS classes toclimit-1 through toclimit-6 not enabled on this wiki? I tried adding class=\"toclimit-3\" to a div containing __TOC__ in the header template used on Wikidata:Property proposal/Place but it doesn't seem to be working (even though the class is transcluded properly). Jc86035 (talk) 14:24, 6 January 2018 (UTC) They are in en:MediaWiki:Common.css but not in d:MediaWiki:Common.css. That's what you need.--Ssola (talk) 06:18, 7 January 2018 (UTC) @Ssola: Thanks. Jc86035 (talk) 10:32, 9 January 2018 (UTC) Wikidata data model \"deficiency\" MD Imtiaz Ahammad Kopiersperre Jklamo ArthurPSmith S.K. Givegivetake fnielsen rjlabs ChristianKl Vladimir Alexiev Parikan User:Cardinha00 MB-one User:Simonmarch User:Jneubert Mathieudu68 User:Kippelboy User:Datawiki30 User:PKM User:RollTide882071 Andber08 Sidpark SilentSpike Susanna √Ön√§s (Susannaanas) User:Johanricher User:Celead User:Finnusertop cdo256 Mathieu Kappler RShigapov User:So9q User:1-Byte pmt Rtnf econterms Dollarsign8 User:Izolight maiki c960657 User:Automotom applsdev Bubalina Fordaemdur DaxServer Laurenz SommerladNotified participants of WikiProject CompaniesThe WD data model is more powerful than RDF because of references and qualifiers. But IMHO it's also weaker in that people are less willing to create items than general RDF nodes.Eg how to model that Hewlett Packard split into HP Inc and Hewlett Packard Enterprise in 2015? I added two \"followed by\" values https://www.wikidata.org/wiki/Q80978#P156 but it really is ONE event with 1 preceding entity and 2 succeeding entities.Guess I could make a prop \"significant event\" but there's no standard property to link the participants (succeeding companies).And I don't think many people would agree to make out the Event as an Item... and to standardize a vocabulary of event participant roles. --Vladimir Alexiev (talk) 16:12, 8 January 2018 (UTC) And I guess we have the same issue in the other direction for mergers? I could argue that if a specific corporate event (like a breakup or merger) had sufficient significance in itself it should have its own item. I'm not sure that all such events deserve an item, but the HP example seems like a good one. ArthurPSmith (talk) 16:55, 8 January 2018 (UTC) Mergers and splits are complicated, but there is no deficiency. In fact in most cases of mergers there is no new entity, just second company is merged to the first and first change its name. The correct way to represent this is no new item, but record appropriate changes to existing items. Problem is that sometime new wiki article is created for \"new\" entity. But that is more likely deficiency of wikpedia, not wikidata. Same for splits, in most cases there is no one old entity and two new entities, just new entity is created and old one change its name. Again the correct way to represent this is one new item for new entity and record appropriate changes to existing item. Again the problem is that sometimes two new articles are created. That is the case of HP, \"Hewlett Packard Enterprise\" is really new entity, but \"HP Inc.\" is nothing but renamed \"Hewlett-Packard Company\". So correct way to record this is rename Hewlett-Packard (Q80978) to HP Inc. (also add appropriate official name (P1448)), leave followed by (P156) and Hewlett Packard Enterprise (Q19923099) but delete followed by (P156) HP Inc. (Q21404084), and at HP Inc. (Q21404084) left just permanent duplicated item (P2959) and Hewlett-Packard (Q80978). But problem it that articles connected to HP Inc. (Q21404084) already exist.--Jklamo (talk) 17:04, 8 January 2018 (UTC) There are different scenarios: A + B = A A + B = C A = A + B A = B + C So we need 4 different event names and 4 different ways to model these events. Snipre (talk) 07:58, 9 January 2018 (UTC) As statements about HP before and after might be considerably different, I'm not entirely convinced by the purely formal approach suggested by Jklamo. --- Jura 10:46, 9 January 2018 (UTC) Wikidata in read-only for 30min on January 9th Hello all,On January 9th, Wikidata will be moved to a dedicated server, in order to allow more resources for the project, due to its growth. (ticket)In order to do this move in good conditions, Wikidata will be in read-only mode on January 9th, from 06:00 UTC to 06:30 UTC. (For some places in the world, it will be January 8th: you can check with your time zone here). During approximately half an hour, humans and bots will be able to read Wikidata, but not to edit it.Thanks for your understanding, Lea Lacroix (WMDE) (talk) 15:37, 3 January 2018 (UTC) Bumping; This is 9.5 hours from when I write (early tomorrow morning, in Europe; 11:30 in Delhi, India; 13:00 Jakarta, Indonesia; 14:00 in Perth WA; 17:00 in Sydney NSW). Andy Mabbett (Pigsonthewing); Talk to Andy; Andy's edits 20:36, 8 January 2018 (UTC) How did it go? Should everything be faster now? --- Jura 10:02, 9 January 2018 (UTC) Everything went fine. Not everything will be faster now ;-) --Lydia Pintscher (WMDE) (talk) 15:13, 9 January 2018 (UTC) How to query old revisions of items? Hi,I am trying to programmatically access old revisions of items. The documentation of the linked data interface mentions it is possible to specify a revision parameter, yet for all cases expect the example of Q42/Revision 112 I get an error (either Not Found (example Q42/Revision 111) or Internal Server Error (example Q42/Revision 1)).Does anyone know why I am getting these errors? Are there any other ways to get old revisions as RDF/JSON/... other than downloading old dumps? In the MediaWikiAPI I did not find revision parameters.Would be thankful for any hints! Ls1g (talk) 16:52, 9 January 2018 (UTC) The revision needs to belong to the specified entity: Q42.json?revision=612406093 works. --Lucas Werkmeister (WMDE) (talk) 16:59, 9 January 2018 (UTC) Thanks! How do I know which revisions belong to an entity? (To explain better, my intention is to make a binary search through revisions until I find one where a specific change I am interested in happened.) Ls1g (talk) 17:14, 9 January 2018 (UTC) For that you would probably use the regular MediaWiki Action API, e.‚ÄØg. something like on Special:ApiSandbox#action=query&prop=revisions&titles=Q42&rvprop=ids&rvlimit=500. --Lucas Werkmeister (WMDE) (talk) 17:18, 9 January 2018 (UTC) However, the Internal Server Error is probably a bug ‚Äì I‚Äôve opened phabricator:T184537 for it. Great, that solves my problem. Thanks! Ls1g (talk) 17:23, 9 January 2018 (UTC) Google Knowledge Graph API I have the Google Knowledge Graph API and a valid key, but can't find the identifier for Kevin Borland (Q40786519). Can someone look it up for me? ‚Äì The preceding unsigned comment was added by Richard Arthur Norton (1958- ) (talk ‚Ä¢ contribs) at 00:47, 2 December 2017‚Äé (UTC). To get this thing archived. --Edgars2007 (talk) 15:38, 10 January 2018 (UTC) How to model 'infant mortality rate'? I'd like to import the infant mortality (Q835884) data from UNESCO. It's defined as the 'number of deaths per 1000 live births', and the imported data would be added to items for countries (using a point in time (P585) qualifier to add yearly data).As the definition is so specific, it seems we may need model it with a new 'infant mortality rate' property. The other option is to create a more general 'mortality rate' property, and then use qualifier applies to part (P518) -> infant (Q998) OR infant mortality (Q835884).I really like this second more general option as we can then use the same property for any other mortality rates of interest. The problem is that 'mortality rate' in itself does not specify exact parameters for how the rate is defined, so we would technically need to add some sort of other qualifier to say for example \"per 1000 people\" - this seems like it gets very messy!So I'm leaning towards the specific property for infant mortality rate. Any feedback or other ideas? Thanks NavinoEvans (talk) 13:38, 9 January 2018 (UTC) The \"per 1000 people\" could be treated as the unit, (if there's not an item for that now, create one) - I don't think that's a significant problem. We have a related property proposal for subpopulation that may be helpful for this. ArthurPSmith (talk) 14:53, 9 January 2018 (UTC) I hadn't thought of that, thanks for the suggestion. I'll wait a bit for any other input but that's swayed me back to going for the more general property. NavinoEvans (talk) 23:31, 9 January 2018 (UTC) License page? I just set up Wikidata:Licensing because I could not find a page with Wikidata's license presented. I suspect that I am mistaken - does anyone know of an existing license page?Where is the page which presents Wikidata's copyright license? I see the license in the footer. Is there anything here like en:Wikipedia:Copyrights or Blue Rasberry (talk) 20:46, 9 January 2018 (UTC) I thought there was a page, but I only found Wikidata:Copyright as an interwikilink of en:Wikipedia:Copyrights. Not much, but hey‚Ä¶ ;-) ‚ÄîMisterSynergy (talk) 20:52, 9 January 2018 (UTC) Thanks, that resolves this. Blue Rasberry (talk) 14:52, 10 January 2018 (UTC) Format of Isidore scholar ID (P4491): identifier of a scholar on Isidore, a platform that collects links to scholarly documents and academic official texts Please comment at Property_talk:P4491. --- Jura 08:59, 10 January 2018 (UTC) Box office in visitors In the film Demain tout commence (Q23899238) box office (P2142) are measured in person (Q215627). Looks like violation of box office (P2142)? - Kareyac (talk) 16:34, 13 January 2018 (UTC) Yes. checkConstraints does not find it, though. --Tagishsimon (talk) 00:44, 14 January 2018 (UTC) Thanks. - Kareyac (talk) 12:11, 14 January 2018 (UTC) This section was archived on a request by: - Kareyac (talk) 16:24, 17 January 2018 (UTC) Custom javascript breaking other scripts Hi, I don't know where else to ask this. I added a one-line jQuery thing to the bottom my common.js. It works as it should, but has the unintended consequence of breaking some of the other scripts I'm using, and I don't understand why. Could someone with some more know-how figure out what I've done wrong? Jon Harald S√∏by (talk) 12:36, 17 January 2018 (UTC) You‚Äôre using $(\".wikibase-title-id\").html().slice(1, -1) to get the item ID and then replace $(\".wikibase-title-id\") with something else. If another gadget tries to read the item ID using the same code, it will no longer work. This could be avoided by using mw.config.get( 'wbEntityId' ) instead (both in your common.js and in the hypothetical gadget or user script that also uses $(\".wikibase-title-id\")). A few random other notes ‚Äì if you keep the wikibase-title-id class on the new element, you can remove most of your custom style (color, font size and margin will be inherited from the class). It probably also makes sense to set the readonly attribute on the <input> ‚Äì I‚Äôm guessing this is just intended as a quick way to copy the entity ID? --Lucas Werkmeister (WMDE) (talk) 12:55, 17 January 2018 (UTC) Thanks Lucas! I tested your suggestions, which worked fine, but the problem persevered ‚Äì I then tried reverting my common.js back to what it was before, and the problem was still there, so I finally figured it wasn't my common.js that was the problem, but rather the Chrome extension I used to test this. Even though the extension's input was empty, it was still enabled for Wikidata.org, and it loaded jQuery even though jQuery is already here via MediaWiki. So when I turned that off, everything works as it should. Thanks for helping! :-) Oh, and yes, it's mainly for copying ID without having to use the mouse to select it, but also useful for a couple of other (Python) scripts I'm running. :-) Jon Harald S√∏by (talk) 13:24, 17 January 2018 (UTC) This section was archived on a request by: Jon Harald S√∏by (talk) 14:13, 17 January 2018 (UTC) Cleanup of unsourced ‚Äúethnic group (P172)‚Äù claims ethnic group (P172) is and has always been a controversial property that has a ‚Äúclaim requires source‚Äù constraint for good reasons; see Property talk:P172#Constraints and Property talk:P172#Rules for Usage for further requirement regarding applicable sources. However, only 861 claims are sourced, and 48269 are not (i.e. 98.2% of all claims violate the constraint, see Wikidata:Database reports/Complex constraint violations/P172 and this query). In my opinion the constraint itself is not debatable, thus I suggest to remove all constraint-violating claims with a bot.We have had a similar discussion for sexual orientation (P91) at Wikidata:Project chat/Archive/2016/08#Unsourced and Wikipedia sourced P91 statements and Wikidata:Project chat/Archive/2016/10#Unsourced sexual orientation (P91) statements, which ultimately led to the removal of unsourced P91 claims. Any thoughs on this one? ‚ÄîMisterSynergy (talk) 22:13, 5 January 2018 (UTC) If you look at #Country of citizenship is Wales you can see that this can be quite a passionate subject matter. Personally I find it a minefield. For some who live in countries where there has been little migration maybe it is easier, however, for those who live in countries with significant migration, in different waves, and resulting inter-marriage it is quite problematic, vaguely or ill-defined, and problematic in its application. So, if we are going to have it then I would agree that it should be sourced by a contemporary source, and the target categorisation should also be notable/encyclopaedic. If we are to bot remove, I believe that any edit summary should have a good link to a page that clearly defines how to add, qualify and cite the link. I would wish to avoid edit wars, complaints about politics, nationalism, etc. ‚Äî billinghurst sDrewth 12:43, 6 January 2018 (UTC) I finished my work on an RfC for Privacy and Living People. Given that ethnic group (P172) likely makes it into a category, the RfC does provide a way to deal with unsourced ethnic group (P172) for living persons. ChristianKl ‚ù™‚úâ‚ù´ 14:02, 6 January 2018 (UTC) As far as I recall, the cleanup on P91 went fairly well. I think we should handle P172 in the same way. It's odd that people ignore the relevant constraint. --- Jura 10:09, 7 January 2018 (UTC) Yes it did go fairly well. After the linked WD:PC discussions were finished, I removed ~5000 P91 claims, and there were no serious complaints raised. A couple of removals have been reverted, particularly by one user, who has always added sources to the reverted claims subsequently. The number of unsourced P91 claims is still low at a bit over 100, although I have never repeated another removal run (no idea whether someone else did so). ‚ÄîMisterSynergy (talk) 10:15, 7 January 2018 (UTC) @Heathart: care to comment here? I just ran SELECT ?item WHERE { ?item p:P172 ?ethnicgroup . ?ethnicgroup ps:P172 wd:Q49085 . MINUS { ?ethnicgroup prov:wasDerivedFrom [] } }
 Try it! and this seems to affect quite a lot of African American artists. I'm not sure if ethnic group (P172) is as controversial as sexual orientation (P91). I don't have a strong opinion on this, but it would be a waste to loose so much date just to be political correct. More practical problem: Sourcing this is going to be hard. Multichill (talk) 12:25, 7 January 2018 (UTC) @Multichill: and all... I think it is important to ‚ÄúUse this property only together with a reference in that the person itself states her/his ethinicity\" but also would propose using notable sources (including Wikipedia or credible news sources) where this information is dependable but secondary, I'm not sure how to state that. Basically if there are no interviews with said person, but they appear in a catalog for an exhibition at the MoMA of paintings by African American Artists, I'd count that as a reference to the persons P172 property. Otherwise I avoid this and agree that something that does not have a reference in this case should be removed. It would be great if all 48269 could be automatically vetted and sourced but I agree the property shouldn't just be assumed. --Heathart (talk) 16:28, 11 January 2018 (UTC) I understand the issue but I would like to discuss another aspect of the problem. For Little Raven (Q535711) I wanted to add the information that he is a member of Arapaho people (Q626136), which is kind of trivial information (it's in his description and the title of the English Wikipedia article). I used ethnic group (P172), and since there is a need for reference, I added \"imported from English Wikipedia\" . But there are lot of other people we have, for instance, pictures on Commons (with good quality metadata) without an article in Wikipedia (yet). Should we reference them with \"imported from Wikimedia Commons\" in these cases ? L√©na (talk) 15:58, 7 January 2018 (UTC) According to the talk page of this property, the requirement for the reference is: ‚ÄúUse this property only together with a reference in that the person itself states her/his ethinicty‚Äù. This means we need external references anyway, and imported from Wikimedia project (P143) references to Wikimedia projects are (in probably all cases) not enough anyway. ‚ÄîMisterSynergy (talk) 15:18, 8 January 2018 (UTC) Comment It would be interesting to hear from contributors who monitoring recent changes/IP edits with this property. --- Jura 08:51, 8 January 2018 (UTC) PetScan I can not log-in WiDar in Petscan to edit Wikidata since last few days due to some strange reason. I used to edit a lot but had to stop bulk editing since last few days. Can anybody tell me what should I do? I can edit from other tools using WiDar.--157.32.0.22 06:28, 12 January 2018 (UTC) Titles for painting (Q3305213) I would like to ask about how original titles for painting (Q3305213) should be modeled. There's title (P1476) and native label (P1705), and I am not sure I see the difference between the two and which should be used to model the original name of the artwork. I see two options: title (P1476) is used for all titles in every language and native label (P1705) only for the original one. Then I do not see how title (P1476) is different from the label/alias. Shouldn't the same thing that goes into title (P1476) be a label? It seems so. title (P1476) is the original title (or titles) in the original language that the creator gave to it or that it was first published/discovered/etc. All the rest of translations go to labels/aliases. But then I am not sure what native label (P1705) is for and whether it should be used for paintings at all? Right now we have 1094 paintings with title (P1476) and 184 paintings with native label (P1705). Clearly title (P1476) is leading. But, I am not sure all usages are correct - i.e. that only original title and not all the translations which were originally never used are there, e.g. see Mona Lisa (Q12418) - it has a Russian title and I am reasonably sure Leonardo da Vinci (Q762) did not speak Russian.So, could we have some agreed rules (maybe recorded in Wikidata:WikiProject_sum_of_all_paintings page?) that all paintings would follow? We can fix non-complying items with a bot or script, it's not hard, but we should figure out the rules first. WikiProject sum of all paintings has more than 50 participants and couldn't be pinged. Please post on the WikiProject's talk page instead. Laboramus (talk) 08:44, 8 January 2018 (UTC) I think there is some bug in the Russian infobox tool that keeps adding P1705. We had the same problem with films. Unfortunately Putnik isn't following up on bugs in his tools when reported in English at Wikidata (User talk:Putnik). --- Jura 08:55, 8 January 2018 (UTC) I use title (P1476) for all titles I can find in authoritative works. For paintings in Danish GLAMs it often means the Danish and the English titles and sometimes a German title. Multiple Danish titles if there are authoritative title changes (I cannot find an example). As an example: A nude woman doing her hair before a mirror (Q6644913). I have never used native label (P1705). ‚Äî Finn √Örup Nielsen (fnielsen) (talk) 16:36, 8 January 2018 (UTC) Most paintings have names made up by later generations. I doubt Leonardo da Vinci ever called it Mona Lisa in any language. So does title (P1476) even apply here? Multichill (talk) 17:09, 8 January 2018 (UTC) True so I am not even sure about title (P1476) - but it looks like native label (P1705) is not the way to go and probably first thing native label (P1705) should be moved to title (P1476) and then we should figure out what to do with title (P1476). I agree that many paintings don't have original titles, but some do, and then if we just use it the same way as labels, why use both? Laboramus (talk) 01:09, 9 January 2018 (UTC) Sounds reasonable! I once wrote Wikidata:WikiProject Visual arts/Item structure#Titles, I don't know of a discussion about artwork titles up to know. Please add advice you consider useful or agreements from here there! The CONA guidelines are also worth seeing. --Marsupium (talk) 14:40, 12 January 2018 (UTC) pywikibot / iterating over SPARQL causes error Tracked in Phabricator Task T138364 Hi project chat,I am running into an error with pywikibot when iterating over the results of a SPARQL query following the instructions from https://www.wikidata.org/wiki/Wikidata:Pywikibot_-_Python_3_Tutorial/Iterate_over_a_SPARQL_queryMy query"""@en;
  dcterms:isPartOf <https://www.wikidata.org//wiki/Wikidata:Project_chat/Archive/2018/01>;
  dcterms:license <https://creativecommons.org/licenses/by-sa/4.0/>;
  sh:prefixes _:genid-4e694113159d4e3db4a1a913894a81d83290-wikidata_prefixes;
  schema:target <https://query.wikidata.org/sparql/>;
  sh:select """PREFIX wikibase: <http://wikiba.se/ontology#>
PREFIX wdt: <http://www.wikidata.org/prop/direct/>
PREFIX bd: <http://www.bigdata.com/rdf#>
SELECT ?item WHERE {
  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }
  OPTIONAL { ?item wdt:P856 ?official_homepage. }
}
LIMIT 50000""" .
